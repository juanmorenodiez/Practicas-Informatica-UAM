{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJXJ_K9jyyTK"
   },
   "source": [
    "# Grado en Ingeniería de Tecnologías y Servicios de Telecomunicación / Grado en Ingeniería Informática\n",
    "### **Asignatura**: Tratamiento de Señales Visuales/Tratamiento de Señales Multimedia I\n",
    "### Práctica 4: Reconocimiento de escenas con Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "Autor: Juan C. SanMiguel (juancarlos.sanmiguel@uam.es), Universidad Autónoma de Madrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K02e8d23y0cH"
   },
   "source": [
    "# Creación de la red neuronal convolucional\n",
    "\n",
    "\n",
    "En este script interativo de python aprenderá a definir redes neuronales convolucionales utilizando la API de alto nivel [Keras](https://www.tensorflow.org/api_docs/python/tf/keras) disponible para Tensorflow\n",
    "\n",
    "Tiempo estimado para completar este script: 15 minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sA-x_l31zXnY"
   },
   "source": [
    "# 1. Preparación del entorno de trabajo\n",
    "\n",
    "A continuación tiene un conjunto de instrucciones para establecer el entorno de trabajo. Verifique que la versión de Python es > 3.6 y la de Tensorflow es 2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PIxJvNDlzhWT",
    "outputId": "0907e2b2-b7e9-47a7-fe58-c85def9f3a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.3.0\n",
      "  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 52 kB/s \n",
      "\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 1.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.13.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.37.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.12.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.42.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.7.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 41.3 MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 22.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.17.3)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (57.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
      "Installing collected packages: numpy, tensorflow-estimator, h5py, gast, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.7.0\n",
      "    Uninstalling tensorflow-estimator-2.7.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.7.0\n",
      "    Uninstalling tensorflow-2.7.0:\n",
      "      Successfully uninstalled tensorflow-2.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed gast-0.3.3 h5py-2.10.0 numpy-1.18.5 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.12\n",
      "Tensorflow 2.3.0\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "#%tensorflow_version 2.x\n",
    "!pip install tensorflow==2.3.0\n",
    "import tensorflow as tf\n",
    "!python --version     # mostrar version de python\n",
    "print('Tensorflow ' + tf.__version__) # mostrar version tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmYpM4cQzCM_"
   },
   "source": [
    "# 1.Definir capas de una red (layers)\n",
    "\n",
    "\n",
    "En esta parte vamos a describir los elementos básicos para definir una red neuronal de tipo *feed-forward*. Este tipo de redes toman una serie de datos de entrada (*input*), éstos son procesados por una serie de capas (*layers*) de manera secuencial y finalmente se genera una salida (*output*) relacionada con la tarea a resolver.\n",
    "\n",
    "Para definir las capas una red, vamos a utilizar el paquete ```tf.keras.layers``` cuya documentación está disponible en este [enlace](https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n",
    "\n",
    "```tf.keras.layers``` permite:\n",
    "*   Definir la estructura de la red, que tendrá algunos parámetros entrenables (i.e. *weights*).\n",
    "*   Definir la secuencia de procesado de los datos para obtener una salida (i.e. *forward pass*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K05iyB_ykEjj"
   },
   "source": [
    "## 1.1 Capa convolucional\n",
    "Primeramente podemos definir *capas convolucionales 2D* mediante la función ``tensorflow.keras.layers.Conv2D`` [[enlace documentación]](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D), que tiene los principales argumentos:\n",
    "*   **filters**: número de mapas de salida (i.e. número de convoluciones o *kernels* que aplicamos sobre los datos de entrada).\n",
    "*   **kernel_size**: tamaño del *kernel* aplicado (tamaño x tamaño)\n",
    "*   **strides**: desplazamiento de la aplicación del operador de convolución\n",
    "*   **padding**: tipo de padding applicado\n",
    "*   **activation**: tipo de función de activación aplicada\n",
    "\n",
    "Además, cuando se utiliza esta capa como la entrada deberá definir el argumento **input_shape** que indica las dimensiones de los datos a procesar.\n",
    "\n",
    "A continuación, se muestra un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FOqUpwekkyQZ",
    "outputId": "5a1ff7bb-676c-4fd6-b886-a03fefa2250e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc9e85eaf90>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fc9b4cb9090>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "# definir primera capa de una red\n",
    "conv1 = layers.Conv2D(filters=32, \n",
    "                       kernel_size=(3, 3), \n",
    "                       strides = (1,1),\n",
    "                       padding = 'same',\n",
    "                       activation='relu', \n",
    "                       input_shape=(32, 32, 3)\n",
    "                      )\n",
    "print(conv1)\n",
    "\n",
    "# definir X capa de una red (observar que no se define la variable \"input_shape\")\n",
    "convX = layers.Conv2D(filters=12, \n",
    "                       kernel_size=(3, 3), \n",
    "                       strides = (1,1),\n",
    "                       padding = 'same',\n",
    "                       activation='relu'\n",
    "                       )\n",
    "print(convX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJIlDKF2l5lZ"
   },
   "source": [
    "##1.2 Capa Fully Connected\n",
    "Posteriormente tenemos *capas con conexión completa* (*fully connected*) mediante la función ``tensorflow.keras.layers.Dense``[[enlace documentación]](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), que tiene los principales argumentos:\n",
    "*   **units**: numero de unidades de salida. \n",
    "*   **activation**: función de activación a utilizar\n",
    "*   **use_bias**: indicador para utilizar sesgo o no\n",
    "\n",
    "El número de unidades de entrada en esta capa, vendrá definido por la capa anterior conectada en la arquitectura.\n",
    "\n",
    "A continuación, se muestra un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcjtXoj6mQHZ",
    "outputId": "b7378899-bb8e-4f7e-b631-cc58f2c60b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fc9b4b00f50>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "fc1 = layers.Dense(units=64, activation='relu', use_bias=True)\n",
    "\n",
    "print(fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnPxR0_nmutN"
   },
   "source": [
    "## 1.3 Capa de Pooling Espacial\n",
    "\n",
    "También exite una etapa dedicada a reducir la dimensionalidad de los datos, cuya nomenclatura es ``tensorflow.keras.layers.MaxPooling2D``[[enlace documentación]](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)\n",
    "\n",
    "\n",
    "pool_size: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "strides: Integer, tuple of 2 integers, or None. Strides values. If None, it will default to pool_size.\n",
    "padding: \n",
    "\n",
    ". Tiene los siguientes argumentos de interés:\n",
    "\n",
    "*   **pool_size**: tamaño del *kernel* aplicado (tamaño x tamaño)\n",
    "*   **stride**: desplazamiento de la aplicación del operador de convolución\n",
    "*   **padding**: tipo de padding applicado\n",
    "\n",
    "A continuación, se muestra un ejemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9q5LZ3DnLry",
    "outputId": "4fe75ec2-e77a-477c-a647-1c83b1c2c07f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fc9e85ea590>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')\n",
    "\n",
    "print(pool1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WhMEYns6Rua"
   },
   "source": [
    "# 2.Definicion de red manual\n",
    "\n",
    "Una vez estudiadas las capas de la red convolucional, vamos a crear una red utilizando el paquete ```tensorflow.keras.model``` [[enlace documentación]](https://www.tensorflow.org/api_docs/python/tf/keras/Model) definiendo cada una de las capas y su secuenciación.\n",
    "\n",
    "En esta parte, vamos a tomar como ejemplo la red LENET http://yann.lecun.com/exdb/lenet/ cuya estructura se visualiza a continuacion:\n",
    "\n",
    "![alt text](http://pytorch.org/tutorials/_images/mnist.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZ5I2E8x69eC"
   },
   "source": [
    "Para crear una red, utilizaremos la instruccion ```add``` de la siguiente manera:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6WobbF6w6Rb-"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "\n",
    "# Numero de clases del dataset a analizar\n",
    "num_classes = 10\n",
    "\n",
    "# indicamos que definiremos un modelo secuencial de red\n",
    "model = models.Sequential()\n",
    "\n",
    "# dimensiones input de mi red\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "# incluir capa convolucional C1\n",
    "model.add(layers.Conv2D(filters=6, \n",
    "                        kernel_size=(3, 3), \n",
    "                        strides = (1,1),\n",
    "                        padding = 'valid',\n",
    "                        activation='relu', \n",
    "                        input_shape=(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)))\n",
    "\n",
    "# incluir average pooling S2\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "# incluir capa convolucional C3\n",
    "model.add(layers.Conv2D(filters=16, \n",
    "                        kernel_size=(3, 3),\n",
    "                        strides = (1,1),\n",
    "                        padding = 'valid', \n",
    "                        activation='relu'))\n",
    "\n",
    "# incluir average pooling S4\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "# convertir el volumen de datos en vector fila para conectarlo con capa FC\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# incluir fully convolutional F5\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "# incluir fully convolutional F6\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "# incluir salida OUTPUT\n",
    "model.add(layers.Dense(units=num_classes, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2V02dJV8JH5"
   },
   "source": [
    "Podemos verificar que el modelo se ha creado correctamente y los parámetros existentes con la instrucción ```summary```:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3nsUNAT-yyEf",
    "outputId": "79e72999-e2ed-476b-fd77-3ab8634e4a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,194\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrnqMy2Y8W8b"
   },
   "source": [
    "# 3.Cargar una red preentrenada\n",
    "\n",
    "Si en lugar de definir una red, queremos cargar arquitecturas preexistentes, podemos utilizar el paquete ```tensorflow.keras.applications``` [[enlace documentación]](https://www.tensorflow.org/api_docs/python/tf/keras/applications).\n",
    "\n",
    "Los argumentos de esta función son:\n",
    "* **include_top**: si se quiere incluir la última capa fully-connected de la arquitectura\n",
    "* **weights**: 'None' para inicialización aleatoria o 'imagenet' (pre-entrenados en ImageNet)\n",
    "* **input_shape**: parámetro opcional que debe ser especificado si include_top=False\n",
    "\n",
    "No obstante, dependiendo de cada red existen argumentos adicionales que pueden consultarse en el siguiente [enlace](https://keras.io/applications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usR4r3tb8p-H",
    "outputId": "038a35e5-5cfc-4e60-c685-9861f54ff98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 7s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.applications as applications\n",
    "\n",
    "# dimensiones de las imagenes a procesar\n",
    "IMG_SHAPE = (128, 128, 3)\n",
    "\n",
    "# modelo pre-entrenado VGG16 con tamaño por defecto (224,224,3)\n",
    "vgg16_model2 = applications.VGG16(include_top=True,\n",
    "                                weights='imagenet')\n",
    "\n",
    "vgg16_model2.summary()\n",
    "\n",
    "# modelo pre-entrenado VGG16 sin incluir capas fc1, fc2 y salida\n",
    "vgg16_model1 = applications.VGG16(input_shape=IMG_SHAPE, \n",
    "                                include_top=False,\n",
    "                                weights='imagenet')\n",
    "\n",
    "vgg16_model1.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de p4_tareaC_net.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
